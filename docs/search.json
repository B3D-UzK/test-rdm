[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "Introduction\nAstrophysics, the study of the universe, relies on vast amounts of data collected from observatories, telescopes, and space missions. Efficient research data management is crucial for extracting insights and advancing our understanding of the cosmos. This involves acquiring, storing, curating, and standardizing data, as well as utilizing advanced computational techniques. Additionally, data preservation and open access principles ensure long-term accessibility and collaboration. In this rapidly advancing field, effective research data management is essential for unraveling the mysteries of the universe."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "DataPolicies.html#range",
    "href": "DataPolicies.html#range",
    "title": "RDM_in_Astro",
    "section": "Range",
    "text": "Range"
  },
  {
    "objectID": "DataPolicies.html#relationship-to-legal-requirements-contracts-with-third-parties",
    "href": "DataPolicies.html#relationship-to-legal-requirements-contracts-with-third-parties",
    "title": "RDM_in_Astro",
    "section": "Relationship to legal requirements/ contracts with third parties",
    "text": "Relationship to legal requirements/ contracts with third parties"
  },
  {
    "objectID": "DataPolicies.html#ownership-of-rightsrights-of-use",
    "href": "DataPolicies.html#ownership-of-rightsrights-of-use",
    "title": "RDM_in_Astro",
    "section": "Ownership of rights/rights of use",
    "text": "Ownership of rights/rights of use"
  },
  {
    "objectID": "DataPolicies.html#data-protection",
    "href": "DataPolicies.html#data-protection",
    "title": "RDM_in_Astro",
    "section": "Data protection",
    "text": "Data protection"
  },
  {
    "objectID": "DataPolicies.html#transfer-of-rights",
    "href": "DataPolicies.html#transfer-of-rights",
    "title": "RDM_in_Astro",
    "section": "Transfer of rights",
    "text": "Transfer of rights"
  },
  {
    "objectID": "DataPolicies.html#basic-principles",
    "href": "DataPolicies.html#basic-principles",
    "title": "RDM_in_Astro",
    "section": "Basic principles",
    "text": "Basic principles"
  },
  {
    "objectID": "DataPolicies.html#data-selection",
    "href": "DataPolicies.html#data-selection",
    "title": "RDM_in_Astro",
    "section": "Data selection",
    "text": "Data selection"
  },
  {
    "objectID": "DataPolicies.html#accesslicensing",
    "href": "DataPolicies.html#accesslicensing",
    "title": "RDM_in_Astro",
    "section": "Access/Licensing",
    "text": "Access/Licensing"
  },
  {
    "objectID": "DataPolicies.html#storage-timestorage-duration",
    "href": "DataPolicies.html#storage-timestorage-duration",
    "title": "RDM_in_Astro",
    "section": "Storage time/storage duration",
    "text": "Storage time/storage duration"
  },
  {
    "objectID": "DataPolicies.html#researchers",
    "href": "DataPolicies.html#researchers",
    "title": "RDM_in_Astro",
    "section": "Researchers",
    "text": "Researchers"
  },
  {
    "objectID": "DataPolicies.html#principles-rdm",
    "href": "DataPolicies.html#principles-rdm",
    "title": "RDM_in_Astro",
    "section": "Principles RDM",
    "text": "Principles RDM"
  },
  {
    "objectID": "DataPolicies.html#data-management-plan-dmp",
    "href": "DataPolicies.html#data-management-plan-dmp",
    "title": "RDM_in_Astro",
    "section": "Data Management Plan (DMP)",
    "text": "Data Management Plan (DMP)"
  },
  {
    "objectID": "DataPolicies.html#project-regulations",
    "href": "DataPolicies.html#project-regulations",
    "title": "RDM_in_Astro",
    "section": "Project Regulations",
    "text": "Project Regulations"
  },
  {
    "objectID": "DataPolicies.html#infrastructure",
    "href": "DataPolicies.html#infrastructure",
    "title": "RDM_in_Astro",
    "section": "Infrastructure",
    "text": "Infrastructure"
  },
  {
    "objectID": "DataPolicies.html#consultingeducationtraining",
    "href": "DataPolicies.html#consultingeducationtraining",
    "title": "RDM_in_Astro",
    "section": "Consulting/Education/Training",
    "text": "Consulting/Education/Training"
  },
  {
    "objectID": "DataPolicies.html#cooperation",
    "href": "DataPolicies.html#cooperation",
    "title": "RDM_in_Astro",
    "section": "Cooperation",
    "text": "Cooperation"
  },
  {
    "objectID": "DataPolicies.html#validityreview",
    "href": "DataPolicies.html#validityreview",
    "title": "RDM_in_Astro",
    "section": "Validity/Review",
    "text": "Validity/Review"
  },
  {
    "objectID": "DataPolicies.html#contact",
    "href": "DataPolicies.html#contact",
    "title": "RDM_in_Astro",
    "section": "Contact",
    "text": "Contact"
  },
  {
    "objectID": "DataPolicies.html#definitions",
    "href": "DataPolicies.html#definitions",
    "title": "RDM_in_Astro",
    "section": "Definitions",
    "text": "Definitions"
  },
  {
    "objectID": "DataPolicies.html#reference-to-related-documents",
    "href": "DataPolicies.html#reference-to-related-documents",
    "title": "RDM_in_Astro",
    "section": "Reference to related documents",
    "text": "Reference to related documents"
  },
  {
    "objectID": "DataPolicies.html#scope",
    "href": "DataPolicies.html#scope",
    "title": "RDM_in_Astro",
    "section": "Scope",
    "text": "Scope\n\nRange\n\n\nRelationship to legal requirements/ contracts with third parties"
  },
  {
    "objectID": "DataPolicies.html#legalethical-aspects",
    "href": "DataPolicies.html#legalethical-aspects",
    "title": "RDM_in_Astro",
    "section": "Legal/Ethical Aspects",
    "text": "Legal/Ethical Aspects\n\nOwnership of rights/rights of use\n\n\nData protection\n\n\nTransfer of rights"
  },
  {
    "objectID": "DataPolicies.html#handling-of-research-data",
    "href": "DataPolicies.html#handling-of-research-data",
    "title": "RDM_in_Astro",
    "section": "Handling Of Research Data",
    "text": "Handling Of Research Data\n\nBasic principles\n\n\nData selection\n\n\nAccess/Licensing\n\n\nStorage time/storage duration"
  },
  {
    "objectID": "DataPolicies.html#responsibilities---researchers",
    "href": "DataPolicies.html#responsibilities---researchers",
    "title": "RDM_in_Astro",
    "section": "Responsibilities - Researchers",
    "text": "Responsibilities - Researchers\n\nResearchers\n\n\nPrinciples RDM\n\n\nData Management Plan (DMP)\n\n\nProject Regulations"
  },
  {
    "objectID": "DataPolicies.html#responsibilities---institution",
    "href": "DataPolicies.html#responsibilities---institution",
    "title": "RDM_in_Astro",
    "section": "Responsibilities - Institution",
    "text": "Responsibilities - Institution\n\nInfrastructure\n\n\nConsulting/Education/Training\n\n\nCooperation"
  },
  {
    "objectID": "DataPolicies.html#validity",
    "href": "DataPolicies.html#validity",
    "title": "RDM_in_Astro",
    "section": "Validity",
    "text": "Validity\n\nValidity/Review\n\n\nContact"
  },
  {
    "objectID": "DataPolicies.html#annexglossary-definitions-references",
    "href": "DataPolicies.html#annexglossary-definitions-references",
    "title": "RDM_in_Astro",
    "section": "Annex/Glossary (definitions, references)",
    "text": "Annex/Glossary (definitions, references)\n\nDefinitions\n\n\nReference to related documents"
  },
  {
    "objectID": "DataPolicies.html",
    "href": "DataPolicies.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "Data policies in astrophysics have been developed to ensure the responsible management, sharing, and utilization of astronomical data. These policies establish guidelines and practices that govern various aspects of data handling, including collection, storage, access, and dissemination. They play a crucial role in promoting transparency, collaboration, and the advancement of scientific research in the field of astrophysics.\nThe formulation of these policies is based on a comprehensive evaluation of existing German research data (RD) policies, a comparison with international recommendations for RD policy development, as well as expert interviews conducted with German universities and a technical college. This process has allowed for the subdivision of key questions and text modules according to the RD policy scheme.\nThe key questions posed during the policy development process draw insights from the evaluation of German RD policies, ensuring alignment with best practices. Additionally, international recommendations for RD policy creation have been taken into account to ensure the policies are robust and globally relevant. Expert interviews with German experts from universities have provided valuable input and perspectives.\nBy incorporating these key questions and text modules into the data policies, the astrophysics community can establish a comprehensive and effective framework for managing research data. This will facilitate data transparency, collaboration, and adherence to best practices, ultimately driving advancements in the field of astrophysics.\n\n\n@article{hiemenz2018empfehlungen, title={Empfehlungen zur Erstellung institutioneller Forschungsdaten-Policies. Das Forschungsdaten-Policy-Kit als generischer Baukasten mit Leitfragen und Textbausteinen f{â€œu}r Hochschulen in Deutschland}, author={Hiemenz, Bea and Kuberek, Monika}, year={2018} }\n1 Preamble\n\n1.1 Aim of the institution, importance of the RDM\n1.2 Standards and principles relating to RDM\n\n2 Scope\n\n2.1 Range\n2.2 Relationship to legal requirements/ contracts with third parties\n\n3 Legal/Ethical Aspects\n\n3.1 Ownership of rights/rights of use\n3.2 Data protection\n3.3 Transfer of rights\n\n4 Handling Of Research Data\n\n4.1 Basic principles\n4.2 Data selection\n4.3 Access/Licensing\n4.4 Storage time/storage duration\n\n5 Responsibilities - Researchers\n\n5.1 Researchers\n5.2 Principles RDM\n5.3 Data Management Plan (DMP)\n5.4 Project Regulations\n\n6 Responsibilities - Institution\n\n6.1 Infrastructure\n6.2 Consulting/Education/Training\n6.3 Cooperation\n\n7 Validity\n\n7.1 Validity/Review\n7.2 Contact\n\n8 Annex/Glossary (definitions, references)\n\n8.1 Definitions\n8.2 Reference to related documents"
  },
  {
    "objectID": "DataPolicies.html#preamble",
    "href": "DataPolicies.html#preamble",
    "title": "RDM_in_Astro",
    "section": "Preamble",
    "text": "Preamble\n\nAim of the institution, importance of the RDM\n\n\nStandards and principles relating to RDM"
  },
  {
    "objectID": "DataManagement.html",
    "href": "DataManagement.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "Data management supports long-term preservation, access, and use of data\nActivities of data management include planning, documenting, formatting, storing, anonymizing, and controlling access to data\nManaging data helps researchers optimize the use of data, collaborate with other researchers, and answer additional questions in the future\nData management is important for responsible research conduct and meeting requirements from funding agencies, journal publishers, and research institutions\nData management sustains the value of data and increases transparency in research projects"
  },
  {
    "objectID": "DataManagement.html#what-are-data",
    "href": "DataManagement.html#what-are-data",
    "title": "RDM in Astro",
    "section": "What Are Data?",
    "text": "What Are Data?\n\nResearch Data Defined\n\nThe fundamental question of the course is what are data, and different organizations have tackled it resulting in various definitions.\nData are different for various disciplines and contexts, and there are multiple types of data in an array of contexts, including numeric and textual data, biological samples, and physical collections.\nResearch data and associated researcher materials should be distinguished, and some of them may be required alongside the data to understand them.\nThe most important concept in the entire course is understanding data in the context of the research data life cycle, from project planning to archiving that data as a research output after the project period has ended.\nKey concepts in these definitions include validity, data sharing among the community, heterogeneity, and contextualization within research communities.\n\n\n\nTypes of Data and Metadata\n\nTypes of data include numeric/tabular data, samples (e.g.Â DNA, blood), physical collections (e.g.Â plant specimens), software programs/code, databases, algorithms, models, and geodatabases.\nBackground data provides contextual information for analysis and includes questionnaires, code books, and descriptions of methodologies.\nResearch products built on data include reports, conference posters, articles, white papers, books, websites, and blogs.\nMetadata is structured information that describes, explains, locates, or represents something else (in this case, research data).\nMinimum metadata elements include who created the data, when it was created/published, and a descriptive name for the dataset. A unique identifier is also necessary to locate the data."
  },
  {
    "objectID": "DataManagement.html#data-management-planning",
    "href": "DataManagement.html#data-management-planning",
    "title": "RDM in Astro",
    "section": "Data Management Planning",
    "text": "Data Management Planning\n\nIntroduction to Data Management Plans\n\nData management is important in the research life cycle.\nA data management plan (DMP) is a formal document that outlines data management strategies during and after a research project.\nMany funding agencies require grantees to submit a DMP as part of the proposal package.\nWriting a comprehensive DMP can encourage researchers to think carefully about data management needs.\nThe transparency and openness of publicly funded research data requires it to be discoverable, accessible, and reusable to the public.\nA well-managed data plan can provide a greater return on investment and benefits for verification, reduction of scientific fraud, promotion of new research, resources for training new researchers, and discouraging unintentional redundancy in research.\n\n\n\nData Management Plan Content\n\nA data management plan (DMP) should describe all major aspects of data management throughout the research life cycle.\nThe Digital Curation Center provides a checklist for a data management plan with questions that should be addressed in the DMP.\nThe checklist includes questions such as: what data will you collect or create? How will the data be collected or created? What metadata documentation will accompany the data? How will you manage ethical and legal issues related to data ownership, privacy, and copyright? How will you store and backup the data? How will you manage access and security? Which data should be retained, shared, and/or preserved? What is the long-term preservation plan for the dataset? How will you share the data? Who will be responsible for data management? What resources will you require to implement your plan?\nThe DMP should justify the data format choice and include storage implications due to the format or volume of the data.\nThe DMP should describe the data collection methods, organizing data files, applying version control, and implementing quality assurance protocols.\nThe DMP should identify provisions for protecting the confidentiality of human participants if the project involves research with human subjects.\nThe DMP should identify the owner of the data and discuss permissions with the data producer if third-party data is being reused.\nThe DMP should include provisions for systematic backups of the data files and describe security measures in detail.\nThe DMP should identify the repository to be used to archive the data and plans to prepare and document the data for long-term preservation.\nThe DMP should identify the mechanism for sharing the data and any restrictions required for data sharing.\nThe DMP should identify who will oversee the implementation of the data management plan and what resources will be required for data management tasks and long-term preservation."
  },
  {
    "objectID": "DataOwnership.html",
    "href": "DataOwnership.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "It is important to clarify the ownership of rights in research collaborations, as it can\naffect the ability of researchers to access and use the data generated by their research.\nIn general, the ownership of rights is determined by the employment contract or specific\nassociation of the researchers involved in the collaboration. It may be necessary to consult with the responsible department or legal department to ensure that the regulations\ngoverning the ownership of rights are properly understood and followed. In addition, the\nregulations for researchers without an employment contract should also be considered.\nLegal regulations, such as the freedom of science guaranteed in the Basic Law, must also\nbe taken into account when determining the ownership of rights in research collaborations.\n\nThe ownership of rights is determined by the employment contract or specific association. In general, the regulations governing the ownership of rights should be clarified\nwith the responsible department or legal department, and the regulations for researchers\nwithout an employment contract should also be identified. Legal regulations, including\nthe freedom of science guaranteed in the Basic Law (Article 5, paragraph 3), should be\ntaken into account. The specific details of the ownership of rights in a research collaboration will depend on the individual circumstances of the collaboration and the agreements\nmade between the involved parties. It is important to clarify and agree on these details\nbefore the collaboration begins.\n\nThe ownership of rights to research data is determined by the employment contract or\nspecific association of the researchers involved in the project. It is important to clarify the\nownership of rights with the responsible department or legal department and to ensure\nthat the regulations for researchers without an employment contract are also addressed.\nLegal regulations, particularly the freedom of science guaranteed in the Basic Law (Art. 5 para. 3), must be observed in all cases.\nAuthorship, patent rights, trademark law, and personal rights are typically regulated\nin the employment contracts or agreements between the researchers and their respective\ninstitutions. These contracts or agreements will outline the ownership and rights of use\nfor any intellectual property created or developed by the researchers during the course\nof their work. In the case of funding contracts, the ownership and rights of use may be\noutlined in the agreement between the funding party and the researcher or institution. It\nis important for all parties involved to carefully review and understand the terms of these\nagreements in order to ensure that ownership and rights of use are properly defined and\nprotected.\n\nThe ownership of non-protectable data may be regulated by the employment contracts\nor agreements between the researchers and the university, or by other agreements (funding\ncontracts). It is important to clarify the ownership of non-protectable data with the\nresponsible department or legal department in order to ensure that all parties involved\nare aware of their rights and obligations.\n\nOwnership of data and its usage rights are regulated by employment contracts and\nother agreements between researchers and their institutions, but it is not clear if personally\nmarking data is part of those agreements. It is also not specified if data is to be marked\nfor personal identification purposes or for other reasons."
  },
  {
    "objectID": "DataOwnership.html#data-protection",
    "href": "DataOwnership.html#data-protection",
    "title": "RDM in Astro",
    "section": "Data protection",
    "text": "Data protection\n\nCompliance with legal/ethical aspects, including data protection, is ensured by adhering to relevant laws and regulations, as well as by following established guidelines and\nprotocols for handling sensitive and personal data. This may involve obtaining informed\nconsent from individuals, anonymizing data, and implementing appropriate security measures to protect data from unauthorized access or use. Additionally, institutions involved\nin the research may have their own policies and procedures in place to ensure compliance\nwith legal/ethical requirements."
  },
  {
    "objectID": "DataOwnership.html#transfer-of-rights",
    "href": "DataOwnership.html#transfer-of-rights",
    "title": "RDM in Astro",
    "section": "Transfer of rights",
    "text": "Transfer of rights\n\nBy regulating the transfer of rights, it can be ensured that data is freely available when\nrights are transferred to third parties, e.g.Â to publishers\n\n- In the case of a transfer of rights of re-use or publication, care should be taken to\nensure that the data remain freely available for scientific purposes.\n\n- All rights to data, in particular the right to further use or publish the data, should\nbe reserved for the Principal Investigators (PI) and should not be outsourced to third\nparties."
  },
  {
    "objectID": "Stakeholders.html",
    "href": "Stakeholders.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "Data Management Stakeholders\n\nThe research lifecycle from the Data Documentation Initiative (DDI) provides a framework for understanding where specific data management practices fall.\nDuring the discovery and planning phase, researchers need to determine what type and format of data they are going to collect, consider ethical issues, and identify potential reusers of the project data. They should also determine the possible costs surrounding data management and identify appropriate data repositories.\nDuring the data collection phase, researchers should follow data management best practices, including file organization, backup and storage strategies, and quality assurance protocols. They should also consider access controls and data security.\nDuring the preparation and data analysis phase, researchers may need to clean, manipulate or process the raw data, and should document any changes to the raw data and create a master version to be analyzed and eventually archived. They should also document analysis procedures, such as modifications to the data, the model used, the code used to run the analysis, and hardware and software specifications.\nDuring the publication and sharing phase, researchers should prepare their data files and other research materials necessary to interpret and reuse the data in the future. They should consult with information professionals or data repository staff and ensure that their data management meets all of the needs and requirements of the repository.\nTrusted repositories perform functions to ensure the long-term management of data, including ensuring the integrity of the data, protecting against data loss, and providing access to data."
  },
  {
    "objectID": "BestPractiesRDM.html",
    "href": "BestPractiesRDM.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "The module introduces the concept of data organization and good file management practices.\nData organization is important because as the research project progresses, a large volume of data is accumulated, and it can be difficult to find specific data files if they are named inaccurately or inconsistently.\nGood file management practices help identify, locate, and use data effectively, and file naming conventions are important when sharing data with collaborators.\nResearch data files and folders need to be labeled and organized in a systematic way to be identifiable and accessible for current and future users.\nConsistent data filing labeling has numerous benefits, including distinguishable data files, easier browsing and retrieval, logical sorting, and prevention of accidental deletion or overwrite.\nGood data file naming prevents confusion when multiple people are working on shared files.\n\n\n\n\n\nThree main criteria to consider when naming research data files:\n\norganization,\ncontext, and\nconsistency.\n\nCommon elements to consider when developing a file naming strategy include version number, date of creation, creator's name, content description, team or department name, publication date, and project number.\nFile naming policy should be scalable and avoid generic names to prevent conflicts.\nFile names should be kept short, relevant, and consistent in format, and should not use special characters.\nBatch renaming software can be used to manage large numbers of files and automate consistent naming conventions.\nBulk renaming tools are available for different operating systems, and can be useful in situations such as assigning sequential numbers, using default names, or transferring files between systems with different naming conventions.\n\n\n\n\n\nDistinguish between different versions of data files consistently\nPick a clear versioning method (e.g.Â using ordinal numbers and decimals)\nAvoid confusing labels such as revision, final, final2, or definitive copy\nRecord changes to data files, even small ones, using auto backup or tracking facilities\nUse version control software such as Subversion and TortoiseSVN for software code\nDelete or discard obsolete versions of data files while retaining original copies\nFurther resources are available for additional information\nMove on to the data file formats module as the next step."
  },
  {
    "objectID": "BestPractiesRDM.html#file-formats-and-transformations",
    "href": "BestPractiesRDM.html#file-formats-and-transformations",
    "title": "RDM in Astro",
    "section": "File Formats and Transformations",
    "text": "File Formats and Transformations\n\nFile Formats\n\nThis module covers file formats, compression, data normalization, and transformations.\nFile formats encode information in a computer file, and software needs to recognize that format to access the content within it.\nThe file format is indicated by an extension in the file name, and files in proprietary formats may require specific software to open them, while open formats can be opened by multiple applications.\nFile types are based on text or binary encoding, and creating or saving data in a text format makes the file human-readable and able to be opened in any operating system.\nOpen, non-proprietary, and widely used file formats are less likely to become obsolete and more likely to be readable well into the future.\nConverting or migrating data files from one format to another may be necessary, and checksum algorithm tools can be used to compare file bits and ensure data integrity.\nCompression involves encoding information in fewer bits than the original representation and can result in lossy or lossless compression.\nZip is a de facto standard lossless compression format used on multiple platforms, while tar files are commonly used in Unix or Linux to bundle multiple files.\n\n\n\nData Transformations\n\nData transformations can be done for various reasons during or after a project\nData transformations involve changing the actual data\nAnonymization is an example of a data transformation that can be used in survey data\nQualitative data can be transformed into quantitative data using coding techniques\nData can be transformed to visualize it more effectively, such as converting ratios to percentages for display on charts\nConfidential or sensitive data can be transformed using aggregation or anonymization\nFurther reading resources are available for file formats, compression, normalization, and data transformations\nThe next module on documentation and data citation is recommended"
  },
  {
    "objectID": "BestPractiesRDM.html#documentation-and-data-citation",
    "href": "BestPractiesRDM.html#documentation-and-data-citation",
    "title": "RDM in Astro",
    "section": "Documentation and Data Citation",
    "text": "Documentation and Data Citation\n\nDocumentation\n\nThis module covers documentation and data citation.\nDocumentation is important for both the creator and other users to understand the data.\nExamples of data documentation include lab notebooks, codebooks, and methodology reports.\nThere are three levels of data documentation: project level, file/database level, and variable/item level.\nProper data citation is important for the credibility and accessibility of research findings.\nData citation should include information on how to access the underlying data.\n\n\n\nData Citation\n\nThe Joint Declaration on Data Citation Principles was issued in 2014 by Force11.\nCiting data helps identify and acknowledge it, promote reproducibility, track usage and impact, and recognize and reward data creators.\nDataCite recommends five minimum citation elements: creator, year of publication, title, publisher, and identifier.\nAdditional elements that may be added are Version and ResourceType.\nThe UK data service recommends using a title that indicates subject matter, geography, and time period.\nWhen citing data, adopt the same style and order of references as your other works, provide more information than less, and include a date of download for dynamic databases.\nGood practice in data documentation and citation contributes to reproducibility of research.\nEven if the data are unpublished, citation principles still apply.\nFurther reading and a next module on storage and security are available."
  },
  {
    "objectID": "BestPractiesRDM.html#storage-and-security",
    "href": "BestPractiesRDM.html#storage-and-security",
    "title": "RDM in Astro",
    "section": "Storage and Security",
    "text": "Storage and Security\n\nStorage\n\nThis module focuses on storing, securing, and backing up research data.\nLosing data can have serious consequences, and hard disk drive crashes are the most common cause of data loss.\nIt's important to store and back up data securely from the outset, and to plan for storage needs and data management costs.\nNetwork drives are highly recommended as they provide a single copy of data that is backed up regularly and held securely.\nPCs, laptops, and external storage devices can also be used but should not be used as the master copy of data.\nCDs, DVDs, and magnetic tapes degrade over time, and errors writing to them are common, so high-quality products from good manufacturers should be used and periodically refreshed.\n\n\n\nBackup\n\nRegular backups are essential for data management to prevent loss due to hard drive failure or accidental deletion.\nThe 3-2-1 principle of backup involves having three copies of files on at least two different media, with one copy stored offsite.\nRegular testing of backups is crucial to ensure they can be restored if needed.\nSeveral questions should be considered when creating a backup strategy, such as how to back up data, how often to back up data, whether to use incremental or full backups, and how to keep track of different versions of data.\nVarious cloud services are available for data backup, including Dropbox, Google Drive, and OneDrive.\nAdvantages of cloud services for backup include no user intervention required, remote offsite backup, encryption and versioning, and multi-platform support.\nRisks of using cloud services for backup include data stored outside the European economic area, slow data restoration, unencrypted data, and service provider bankruptcy.\n\n\n\nData security\n\nData security means keeping your research data safe from damage, theft, breach of confidentiality, and premature release.\nConsider who needs access to the data and how to enforce permissions and restrictions.\nHave a clear policy on who can make copies of the data and store them on mobile devices.\nInstall up-to-date antivirus software and consider physical security for highly sensitive data.\nUse strong user names and passwords, avoid obvious phrases, don't write them down, and don't use the same password for multiple accounts.\nAvoid signing into secure sites from untrusted computers or networks.\n\n\n\nEncryption\n\nEncryption is the process of converting data into an unreadable code that requires an encryption key or password to be accessed.\nEncryption protects data from disclosure in case of loss or theft of a laptop or storage device.\nMedium or high-risk personal or business information must be encrypted if it leaves the university environment.\nA strong encryption password is necessary for data protection, and a reliable backup procedure is essential for password management.\nDifferent encryption software packages are available, and IT support can advise on encrypted flash drive purchases.\nFile deletion is not enough to remove sensitive data from a computer, and three main options for permanent data removal include data erasure, degaussing, and physical destruction.\nFurther reading and resources are available for storage, backup, and security."
  },
  {
    "objectID": "Archiving.html",
    "href": "Archiving.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "Archiving digital data is crucial for long-term accessibility and usability.\nTrustworthy repositories can provide strategies to preserve data authenticity and integrity.\nUnderstanding preservation needs, authenticity, integrity, and metadata is important.\nDigital data are at risk due to benign neglect, bit rot, obsolescence, and insufficient documentation.\nBit rot is the degradation or corruption of machine-readable information over time.\nObsolescence occurs when hardware or software becomes outdated and data becomes trapped.\nInsufficient documentation makes it impossible to interpret data in the future.\nComplete and appropriate documentation and metadata are essential for long-term data preservation.\n\n\n\n\n\nPreservation of digital content aims to ensure authenticity and integrity\nAuthenticity means the data is genuine and free from tampering\nEstablishing authenticity requires both researchers and data repositories to have procedures and documentation in place\nBest practices for maintaining authenticity include maintaining a single master file, regulating write access, recording all changes, and archiving copies of master files\nIntegrity means the digital object has not been corrupted over time or in transit between storage locations or systems\nBest practices for maintaining integrity include backing up critical files, storing master files in open source formats, verifying backup copies, storing copies on two types of storage media, and copying/migrating files to new storage media every 2-5 years\nTechnology has increased our ability to collect and analyze data but also has vulnerabilities, requiring an active preservation strategy based on standards and best practices.\n\n\n\n\n\nMetadata is structured information that describes, explains, locates, or represents something else and is necessary for resource discovery, organization, interoperability, identification, and preservation.\nThere are three types of metadata: descriptive, administrative, and structural.\nDescriptive metadata is used for discovery and identification, including information such as title, author, and abstract.\nAdministrative metadata is structured information regarding the management and tracking of data over time and can be rights management or preservation metadata.\nStructural metadata describes the physical or logical structure of digital objects.\nMetadata standards often require adherence to specific representation rules and controlled vocabularies to ensure consistency in data entry and authoritative use of terms.\nGood standardized metadata allows for interoperability across systems, data structures, and interfaces, and facilitates the efficient dissemination of digital materials.\nThe open archive initiative protocol for metadata harvesting (OAI-PMH) is an example of how standardized metadata can be shared across distributed systems."
  },
  {
    "objectID": "Archiving.html#trustworthy-repositories",
    "href": "Archiving.html#trustworthy-repositories",
    "title": "RDM in Astro",
    "section": "Trustworthy Repositories",
    "text": "Trustworthy Repositories\n\nDemonstrating Trustworthiness\n\nTrustworthy repositories are crucial for the long-term preservation of data.\nData repositories oversee the long-term storage and preservation of data and come in different types, including domain, institutional, and location-specific.\nIt's important to talk to repository staff early in the research data life cycle to understand specific data management requirements.\nTo ensure the trustworthiness of a repository, they must demonstrate compliance with standards and best practices through transparent policies and seek audit and certification.\nAdhering to standards and best practices is essential to achieving trustworthiness.\nTransparent policies and procedures are necessary for repositories to demonstrate their trustworthiness, and they should make their archival and digital preservation policies readily available to stakeholders.\nThe Data Seal of Approval, DRAMBORA, and ISO 16363 Audit and Certification of Trustworthy Digital Repositories are examples of audit schemes used to assess the trustworthiness of digital repositories based on adherence, standards, and best practices.\n\n\n\nData Curation Standards and Best Practices (Part 1)\n\nISO 14721 is a reference model for an open archival information system (OAIS).\nOAIS defines elements and processes within digital repositories, and establishes responsibilities for long-term preservation of digital information.\nRepositories that consider themselves to be OAIS archives are presumed to have mechanisms and workflows in place to properly safeguard digital materials for a designated community.\nOAIS model has six functional entities: Ingest, Archival Storage, Data Management, Administration, Preservation, and Access.\nIngest function performs several tasks to establish evidence of authenticity, ensure files are in proper formats, and normalize files to formats optimal for long-term preservation.\nStandard ingest procedures include consideration of sustainability and use factors that affect feasibility and cost of long-term file preservation.\nPreservation optimization presumes that supplementary documentation is included with the file to enable appropriate interpretation and use of the data.\nOnce ingest tasks have been completed, the SIP becomes an AIP which is managed by the archival storage function.\nData management function provides functionality for generating, maintaining, and accessing metadata to document files housed in archival storage.\nAccess function coordinates requests and delivers the final dissemination information package (DIP) to users who can retrieve data files.\n\n\n\nData Curation Standards and Best Practices (Part 2)\n\nPreservation planning function provides recommendations for preservation and planning strategies to ensure that data are accessible and understandable to users over time.\nMigration and emulation are common preservation strategies to protect against data loss due to obsolescence.\nPreservation planning involves ongoing evaluation of archival materials to identify file migration requirements, recommend changes to archive processes and policies, and report any risks.\nAdministration function handles data submission agreements with data producers, establishes quality standards, and manages infrastructure configurations.\nTrustworthy repositories have short-term and long-term business plans for sustainability with transparent accounting practices, and they analyze and document financial risks, investments and expenditures.\nStoring copies of digital content in geographically distributed locations and collaborative partnerships can help protect against physical losses from disasters or organizational failure.\nEconomics sustainability for long term preservation is an ongoing concern in the field of data archiving because the cost of long term preservation is still largely unclear.\nTrustworthy data repositories make a verifiable commitment to archiving data and expend significant amounts of labor, funding, research and assessment to safeguard data."
  },
  {
    "objectID": "Networking.html",
    "href": "Networking.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "DMA\nHMC\n\n\n\n\n\n\nB3D\nSFB"
  },
  {
    "objectID": "SharingData.html",
    "href": "SharingData.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "Benefits of data sharing:\n\nReinforces open scientific inquiry\nSupports verification and replication of original results\nPromotes new research and testing of alternative methods\nEncourages collaboration and multiple perspectives\nProvides important teaching resources\nReduces costs by avoiding duplicate data collection efforts\nProtects against faulty or fraudulent data\nEnhances visibility and overall impact of research projects\nPreserves data for future use\nHelps the broader community and individual researchers do better research\n\nKey players in data sharing are the data creator/producer, secondary data user, and data repository\nData repository plays a key role in enhancing discovery and reuse of data and creating formal data citation\nSharing data is encouraged by funders and required in some cases\nData sharing benefits both the broader research community and individual researchers.\n\n\n\n\nChallenges to data sharing:\n\nMaking data shareable takes time and effort\nPerceived risks from loss of control of the data\nData contained confidential or sensitive information\nOwnership of the data may be unclear or problematic\nLack of incentives for sharing data\n\nAdditional challenge: lack of experience and knowledge of data management\nResearchers and information professionals can overcome these challenges by applying data management practices.\n\n\n\n\nLack of career incentives is an obstacle to sharing data.\nData citation provides a standardized method for citing data, and can be used to reward researchers for sharing their data.\nThe Joint Declaration of Data Citation Principles establishes principles for data citation, including credit and attribution, evidence, unique identification, access, persistence, specificity and verifiability, and interoperability and flexibility.\nDataCite is a group that works with data repositories to assign persistent identifiers such as DOIs to data, supporting simple and effective methods of data citation, discovery, and access.\nProper citation of datasets supports reproducibility of research, ensures proper credit for researchers, and enables tracking of data reuse.\nResearchers should consider whether the repository they choose supports the creation of unique data citations that embody the Joint Declaration of Data Citation Principles."
  },
  {
    "objectID": "SharingData.html#enabling-sharing",
    "href": "SharingData.html#enabling-sharing",
    "title": "RDM in Astro",
    "section": "Enabling Sharing",
    "text": "Enabling Sharing\n\nProtecting Confidentiality\n\nResearchers have an ethical obligation to protect the privacy of study participants when collecting data that deals with human subjects.\nConfidentiality breaches can have serious consequences, including negative impacts on a researcher's career and institution, as well as legal sanctions.\nProtecting confidentiality requires careful consideration and special handling of not only direct identifiers, but also indirect identifiers.\nAnonymizing qualitative data is best done using a pre-planned anonymization scheme that modifies the qualitative dataset to protect respondent confidentiality.\nThere are other strategies currently being developed to protect confidential data, but the most common strategy remains to anonymize data by removing variables, applying statistical techniques, or redacting information to lessen the potential for identifying an individual.\nResearchers should consider future research questions and carefully consider a variable's analytic importance to determine the best strategy for anonymizing data to maximize usability, and may consult their institutional review board, statistical experts, or information professionals.\n\n\n\nIntellectual Property and Data Ownership\n\nData ownership and intellectual property rights can complicate sharing research data.\nIntellectual property rights apply to any work created or invented with intellectual effort.\nDifferent forms of research data can have different intellectual property rights and legal jurisdictions.\nResearchers should resolve any data ownership issues before sharing data.\nData ownership can be complicated due to multiple stakeholders and collaborations.\nResearchers should come to an agreement on data usage and ownership at the beginning of a project.\nInstitutional policies and funder policies can influence data ownership and sharing.\nResearchers may need permission from data producers to share proprietary data.\nInformation and legal professionals can assist researchers in determining policies that affect data ownership.\n\n\n\nAccess\n\nSharing research data has benefits and challenges.\nAccess to data may vary based on external limitations or researchers' needs.\nData ownership issues or data containing sensitive or confidential information may affect how and where a researcher provides access.\nThree types of restrictions that are commonly placed on data: embargos, technological access restrictions, and data use agreements.\nEmbargos are a specified period of time when access to data will be restricted.\nTechnological access restrictions may require users to log in to a particular system and authenticate the relationship to an institution to access certain data.\nData use agreements explicitly outline an agreement between the data producer and secondary data user.\nIdeally, researchers should make data as open as possible, but this may not always be feasible.\nApplying a standard Creative Commons license can positively impact the potential for reuse.\nCreative Commons provides a robust legal code, a human-readable summary, and a machine-readable layer of code that can help make resources interoperable across systems.\nFive main Creative Commons license categories: Attribution, NonCommercial, No Derivative Works, ShareAlike, and CC0.\nResearchers should explain restrictions within the terms of use and apply a standard license to enable informed reuse."
  },
  {
    "objectID": "Training.html",
    "href": "Training.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "CÂ³RDM aims to centralize services and expertise related to research data management (RDM). It provides guidance to researchers at the University of Cologne throughout the entire research data life cycle, while actively supporting the systematic development of a scalable research data infrastructure through demand-driven services.\nhttps://fdm.uni-koeln.de/en/c3rdm-team"
  },
  {
    "objectID": "Training.html#mantra",
    "href": "Training.html#mantra",
    "title": "RDM in Astro",
    "section": "MANTRA",
    "text": "MANTRA\nMANTRA offers a no-cost online course tailored for individuals involved in research projects that entail the management of digital data.\nhttps://mantra.ed.ac.uk/"
  },
  {
    "objectID": "ELabNotebook.html",
    "href": "ELabNotebook.html",
    "title": "RDM in Astro",
    "section": "",
    "text": "An Electronic Lab Notebook (ELN) is a digital tool that mimics the format of a paper lab notebook, allowing researchers to record protocols, observations, notes, and other data using their computer or mobile device. ELNs offer numerous benefits compared to traditional paper notebooks, such as promoting good data management practices, ensuring data security, facilitating auditing, and enabling collaboration. Certain ELNs can also manage inventories, track equipment maintenance schedules, and provide specialized scientific tools for tasks like chemical drawing or molecular biology.\n\n\nELNs align with FAIR Principles (Findable, Accessible, Interoperable, Reusable), endorsed by the research community and organizations like the National Institutes of Health. They enable effective oversight by Principal Investigators (PIs) or Core Facility managers. Collaborative data sharing and documentation become effortless with ELNs. They eliminate challenges arising from illegible handwriting and damaged paper notebooks. ELNs also safeguard against data loss when researchers transition. Certain ELNs integrate seamlessly with platforms like Mendeley, Dataverse, PubMed, and other applications, streamlining the publishing and research processes.\n\n\n\n1. Dedicated Tablets: Providing researchers with dedicated tablets specifically for lab use can help streamline computer-related tasks in the lab setting.\n2. Voice Input or OCR Plugins: Utilizing voice input or optical character recognition (OCR) plugins can facilitate data entry, making it easier and faster to record observations and other experiment-related information.\n3. Time-Saving Features: Leveraging time-saving features within an Electronic Lab Notebook (ELN), such as linking experiments to raw data files and results, and automatically timestamping entries, helps maintain data provenance and efficiency.\n4. Integration with Research Software: Integrating the ELN with other research software enables seamless data capture and information management, simplifying the overall experimental process.\n\n\n\n\n\nLabguru is a comprehensive, cloud-based platform that combines features of an Electronic Lab Notebook (ELN), Laboratory Information Management System (LIMS), and informatics software. Designed for life science research and industry, Labguru offers a secure solution for managing laboratory data, inventory, and workflows.\nThis platform includes molecular biology and chemistry tools, facilitating experimental design, data capture, and project management. With Labguru, scientists can create customizable experiment templates, integrate protocols and standard operating procedures (SOPs), and collaborate on research projects. The platform enhances data quality, streamlines workflows, and reduces costs.\nLabguru is accessible on both desktop and mobile devices through cloud-based access. It is a part of the Holtzbrinck Publishing Group and serves a diverse user base of over 120,000 scientists worldwide. Its users range from startups, universities, and research institutes to some of the largest pharmaceutical companies.\n\n\n\nSciNote is an advanced cloud-based electronic lab notebook (ELN) that is trusted by prestigious organizations like the FDA, USDA, NIH, and the European Commission. It has a user base of over 90,000 scientists across 100 countries. SciNote stands out for its comprehensive features, including inventory management, compliance tools, and team management capabilities. It offers top-rated data management functionalities such as inventory tracking, protocol and SOP management, regulatory compliance, team collaboration, integrations, project management, and robust data security measures. With headquarters in Middleton, WI, USA, SciNote also has offices in Europe to serve its global community of users.\n\n\n\nLabWare is a renowned global leader in laboratory information management systems (LIMS). With over 30 years of experience, LabWare has served more than 3,000 customers worldwide, including prestigious organizations such as NIH, USDA, GSK, Pfizer, Hershey, Caterpillar, and Chevron. LabWare boasts an impressive 98% customer satisfaction rate.\nLabWareâ€™s laboratory automation platform is designed to ensure data integrity, compliance, and accurate test results, ultimately leading to more efficient laboratory operations. Customers have the flexibility to choose between two options: the cost-optimized and fully validated LabWare SaaS LIMS or the industry-optimized and fully customizable LabWare LIMS/ELN. Both solutions cater to the specific needs of laboratories, offering advanced functionality and reliable performance."
  }
]